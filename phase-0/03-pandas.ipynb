{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b7b8668",
   "metadata": {},
   "source": [
    "# üêº Master Pandas: From Zero to Job-Ready\n",
    "\n",
    "**Prerequisites:** Basic Python, Basic NumPy.\n",
    "**Goal:** Load, clean, manipulate, and analyze tabular data.\n",
    "\n",
    "-----\n",
    "\n",
    "## Part 1: The Two Core Structures\n",
    "\n",
    "*Start here. Everything in Pandas is built on these two objects.*\n",
    "\n",
    "### 1.1 The Series (1D)\n",
    "\n",
    "Think of a **Series** as a single column in Excel or a specialized Python list. It has an **Index** (labels) and **Values**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06de0b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: numpy in /home/dat/data/learning/deep-learning-for-beginner/.venv/lib/python3.13/site-packages (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/dat/data/learning/deep-learning-for-beginner/.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/dat/data/learning/deep-learning-for-beginner/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.3-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/3\u001b[0m [pandas]‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/3\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pandas-2.3.3 pytz-2025.2 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b2dc6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Series:\n",
      " 0    10\n",
      "1    20\n",
      "2    30\n",
      "Name: Product Price, dtype: int64\n",
      "\n",
      "Labeled Series:\n",
      " Apple     10\n",
      "Banana    20\n",
      "Cherry    30\n",
      "dtype: int64\n",
      "\n",
      "Access by Label (Apple): 10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a Series from a list\n",
    "# Note: Pandas automatically creates an integer index (0, 1, 2...)\n",
    "prices = pd.Series([10, 20, 30], name=\"Product Price\")\n",
    "print(\"Simple Series:\\n\", prices)\n",
    "\n",
    "# Custom Index (Like a Map/Dictionary keys)\n",
    "# You can access data by position OR by label\n",
    "prices_labeled = pd.Series([10, 20, 30], index=['Apple', 'Banana', 'Cherry'])\n",
    "print(\"\\nLabeled Series:\\n\", prices_labeled)\n",
    "\n",
    "print(\"\\nAccess by Label (Apple):\", prices_labeled['Apple'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f646b0df",
   "metadata": {},
   "source": [
    "\n",
    "### 1.2 The DataFrame (2D)\n",
    "\n",
    "Think of a **DataFrame** as an entire Excel sheet or a SQL table. It is a collection of Series sharing the same Index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "352ecc13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>25</td>\n",
       "      <td>New York</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>30</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>35</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David</td>\n",
       "      <td>40</td>\n",
       "      <td>Houston</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age         City  Salary\n",
       "0    Alice   25     New York   70000\n",
       "1      Bob   30  Los Angeles   80000\n",
       "2  Charlie   35      Chicago  120000\n",
       "3    David   40      Houston   90000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Age': [25, 30, 35, 40],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston'],\n",
    "    'Salary': [70000, 80000, 120000, 90000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df\n",
    "# Note: Jupyter renders DataFrames as nice HTML tables. \n",
    "# If you are in a standard script, use print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89389ca2",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2: Inspecting Data (The \"Hello World\" of Data Analysis)\n",
    "\n",
    "*Before you touch data, you must understand it. These are the first commands you run on ANY new dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeef6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Peek at the data\n",
    "print(\"First 2 rows:\\n\", df.head(2))\n",
    "\n",
    "# 2. Technical Summary (CRITICAL)\n",
    "# Checks for: Missing values (Null), Data Types (int, object/string)\n",
    "print(\"\\n--- Info ---\")\n",
    "df.info() \n",
    "\n",
    "# 3. Statistical Summary\n",
    "# Instantly gives you Mean, Min, Max, Percentiles for numeric columns\n",
    "print(\"\\n--- Description ---\")\n",
    "print(df.describe())\n",
    "\n",
    "# 4. Shape (Rows, Columns)\n",
    "print(f\"\\nShape: {df.shape}\") # (4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f608303e",
   "metadata": {},
   "source": [
    "## Part 3: Selection & Filtering (The \"Where\" Clause)\n",
    "\n",
    "*This is the most common point of confusion. We use `.loc` and `.iloc`.*\n",
    "\n",
    "  * **`.loc[row_label, col_label]`**: \"Location\". Uses **names**. (Think: \"Get me the row named 'Bob'\").\n",
    "  * **`.iloc[row_index, col_index]`**: \"Integer Location\". Uses **positions**. (Think: \"Get me row 0\").\n",
    "\n",
    "<!-- end list -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a1c9a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ages:\n",
      " 0    25\n",
      "1    30\n",
      "2    35\n",
      "3    40\n",
      "Name: Age, dtype: int64\n",
      "\n",
      "Age and City:\n",
      "    Age         City\n",
      "0   25     New York\n",
      "1   30  Los Angeles\n",
      "2   35      Chicago\n",
      "3   40      Houston\n",
      "\n",
      "--- .loc Example (Bob) ---\n",
      "Age                30\n",
      "City      Los Angeles\n",
      "Salary          80000\n",
      "Name: Bob, dtype: object\n",
      "\n",
      "--- .iloc Example (Index 1) ---\n",
      "Name              Bob\n",
      "Age                30\n",
      "City      Los Angeles\n",
      "Salary          80000\n",
      "Name: 1, dtype: object\n",
      "\n",
      "High Earners:\n",
      "       Name  Age     City  Salary\n",
      "2  Charlie   35  Chicago  120000\n",
      "3    David   40  Houston   90000\n",
      "\n",
      "Complex Filter:\n",
      "       Name  Age     City  Salary\n",
      "2  Charlie   35  Chicago  120000\n"
     ]
    }
   ],
   "source": [
    "# Let's set 'Name' as the index to demonstrate .loc clearly\n",
    "df_labeled = df.set_index('Name')\n",
    "\n",
    "# --- 1. Selecting Columns ---\n",
    "# Returns a Series\n",
    "print(\"Ages:\\n\", df['Age']) \n",
    "\n",
    "# Returns a DataFrame (Double brackets)\n",
    "print(\"\\nAge and City:\\n\", df[['Age', 'City']])\n",
    "\n",
    "# --- 2. Selecting Rows (The confusion killer) ---\n",
    "\n",
    "# .loc example: \"Give me Bob's data\"\n",
    "print(\"\\n--- .loc Example (Bob) ---\")\n",
    "print(df_labeled.loc['Bob'])\n",
    "\n",
    "# .iloc example: \"Give me the 2nd row (Index 1)\"\n",
    "print(\"\\n--- .iloc Example (Index 1) ---\")\n",
    "print(df.iloc[1])\n",
    "\n",
    "# --- 3. Conditional Selection (The 'SQL Where' clause) ---\n",
    "# Syntax: df[condition]\n",
    "\n",
    "# Who earns more than 85k?\n",
    "high_earners = df[df['Salary'] > 85000]\n",
    "print(\"\\nHigh Earners:\\n\", high_earners)\n",
    "\n",
    "# Multiple conditions: Use & (AND), | (OR) and parentheses!\n",
    "# Age > 30 AND City is Chicago\n",
    "subset = df[(df['Age'] > 30) & (df['City'] == 'Chicago')]\n",
    "print(\"\\nComplex Filter:\\n\", subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da291b9",
   "metadata": {},
   "source": [
    "## Part 4: Data Cleaning (The 80% of the Job)\n",
    "\n",
    "*Real world data is messy. Here is how to fix it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32040f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Messy Data:\n",
      "   Product    Price\n",
      "0       A      100\n",
      "1       B      200\n",
      "2       C  Missing\n",
      "3       A      100\n",
      "4     NaN      300\n",
      "\n",
      "Dropped Nulls:\n",
      "   Product    Price\n",
      "0       A      100\n",
      "1       B      200\n",
      "2       C  Missing\n",
      "3       A      100\n",
      "\n",
      "Filled Nulls:\n",
      "    Product    Price\n",
      "0        A      100\n",
      "1        B      200\n",
      "2        C  Missing\n",
      "3        A      100\n",
      "4  Unknown      300\n",
      "\n",
      "Duplicates Removed:\n",
      "   Product    Price\n",
      "0       A      100\n",
      "1       B      200\n",
      "2       C  Missing\n",
      "4     NaN      300\n",
      "\n",
      "Fixed Types:\n",
      "   Product  Price\n",
      "0       A  100.0\n",
      "1       B  200.0\n",
      "2       C    NaN\n",
      "3       A  100.0\n",
      "4     NaN  300.0\n"
     ]
    }
   ],
   "source": [
    "# Let's create a messy DataFrame\n",
    "messy_data = pd.DataFrame({\n",
    "    'Product': ['A', 'B', 'C', 'A', np.nan], # Duplicate 'A', Missing Value\n",
    "    'Price': ['100', '200', 'Missing', '100', '300'] # String type instead of Int, one garbage value\n",
    "})\n",
    "\n",
    "print(\"Original Messy Data:\\n\", messy_data)\n",
    "\n",
    "# 1. Handling Missing Values\n",
    "# Option A: Drop them\n",
    "print(\"\\nDropped Nulls:\\n\", messy_data.dropna())\n",
    "\n",
    "# Option B: Fill them\n",
    "print(\"\\nFilled Nulls:\\n\", messy_data.fillna('Unknown'))\n",
    "\n",
    "\n",
    "# 2. Handling Duplicates\n",
    "print(\"\\nDuplicates Removed:\\n\", messy_data.drop_duplicates())\n",
    "\n",
    "\n",
    "# 3. Fixing Data Types (The hardest part)\n",
    "# 'Price' is currently an 'object' (string) because of the word \"Missing\"\n",
    "# We need to coerce errors (turn \"Missing\" into NaN) then convert to float.\n",
    "\n",
    "messy_data['Price'] = pd.to_numeric(messy_data['Price'], errors='coerce')\n",
    "print(\"\\nFixed Types:\\n\", messy_data)\n",
    "# Now 'Price' is float, and \"Missing\" became NaN (Not a Number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1997fd8a",
   "metadata": {},
   "source": [
    "\n",
    "## Part 5: Feature Engineering (Creating New Data)\n",
    "\n",
    "*Creating new columns based on existing ones.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acaabe2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Columns:\n",
      "       Name  Age         City  Salary  Salary_Monthly   Level\n",
      "0    Alice   25     New York   70000     5833.333333  Junior\n",
      "1      Bob   30  Los Angeles   80000     6666.666667  Junior\n",
      "2  Charlie   35      Chicago  120000    10000.000000  Junior\n",
      "3    David   40      Houston   90000     7500.000000  Senior\n"
     ]
    }
   ],
   "source": [
    "# Restore our clean dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 1. Simple Math\n",
    "df['Salary_Monthly'] = df['Salary'] / 12\n",
    "\n",
    "# 2. The .apply() method (The Power Tool)\n",
    "# Apply a custom python function to every row or column.\n",
    "# Note: Slower than vectorization, but very flexible.\n",
    "\n",
    "def classify_age(age):\n",
    "    return \"Senior\" if age > 35 else \"Junior\"\n",
    "\n",
    "df['Level'] = df['Age'].apply(classify_age)\n",
    "\n",
    "print(\"Added Columns:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddbd03a",
   "metadata": {},
   "source": [
    "## Part 6: Grouping & Aggregation\n",
    "\n",
    "*The \"Pivot Table\" concept. This is the Split-Apply-Combine pattern.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "655bf2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sales by Dept:\n",
      " Department\n",
      "HR        110\n",
      "IT       2200\n",
      "Sales     500\n",
      "Name: Sales_Value, dtype: int64\n",
      "\n",
      "Detailed Stats:\n",
      "               mean   max  count\n",
      "Department                     \n",
      "HR            55.0    60      2\n",
      "IT          1100.0  1200      2\n",
      "Sales        250.0   300      2\n"
     ]
    }
   ],
   "source": [
    "# Let's expand our dataset\n",
    "df_sales = pd.DataFrame({\n",
    "    'Department': ['Sales', 'Sales', 'HR', 'HR', 'IT', 'IT'],\n",
    "    'Employee': ['John', 'Jane', 'Mike', 'Sue', 'Chris', 'Pat'],\n",
    "    'Sales_Value': [200, 300, 50, 60, 1000, 1200]\n",
    "})\n",
    "\n",
    "# Question: What is the total Sales_Value per Department?\n",
    "\n",
    "# 1. Split: Group by 'Department'\n",
    "grouped = df_sales.groupby('Department')\n",
    "\n",
    "# 2. Apply & Combine: Calculate Sum\n",
    "print(\"Total Sales by Dept:\\n\", grouped['Sales_Value'].sum())\n",
    "\n",
    "# You can do multiple aggregates at once\n",
    "print(\"\\nDetailed Stats:\\n\", grouped['Sales_Value'].agg(['mean', 'max', 'count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b902ca",
   "metadata": {},
   "source": [
    "## Part 7: Merging (Joins)\n",
    "\n",
    "*Combining two tables. If you know SQL, this is `JOIN`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34ffc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.DataFrame({\n",
    "    'UserID': [1, 2, 3],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie']\n",
    "})\n",
    "\n",
    "emails = pd.DataFrame({\n",
    "    'UserID': [2, 3, 4],\n",
    "    'Email': ['bob@email.com', 'charlie@email.com', 'david@email.com']\n",
    "})\n",
    "\n",
    "# INNER JOIN (Default): Only keeps keys present in BOTH\n",
    "# Alice (1) and David (4) get dropped.\n",
    "merged_inner = pd.merge(users, emails, on='UserID', how='inner')\n",
    "print(\"Inner Join:\\n\", merged_inner)\n",
    "\n",
    "# LEFT JOIN: Keeps everything from Left (Users), fills missing Right matches with NaN\n",
    "# Alice is kept, David is ignored.\n",
    "merged_left = pd.merge(users, emails, on='UserID', how='left')\n",
    "print(\"\\nLeft Join:\\n\", merged_left)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53726ef5",
   "metadata": {},
   "source": [
    "## Part 8: Time Series (Bonus but Essential)\n",
    "\n",
    "*Pandas was originally created for financial time series data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cd76561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series:\n",
      "             Sales\n",
      "Date             \n",
      "2024-01-01    100\n",
      "2024-01-02    120\n",
      "2024-01-03    150\n",
      "2024-01-04    110\n",
      "2024-01-05    200\n",
      "\n",
      "Sales on Jan 3rd: Sales    150\n",
      "Name: 2024-01-03 00:00:00, dtype: int64\n",
      "\n",
      "2-Day Average:\n",
      "             Sales\n",
      "Date             \n",
      "2024-01-01  110.0\n",
      "2024-01-03  130.0\n",
      "2024-01-05  200.0\n"
     ]
    }
   ],
   "source": [
    "# Create a date range\n",
    "dates = pd.date_range(start='2024-01-01', periods=5, freq='D') # D = Day\n",
    "\n",
    "ts_df = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Sales': [100, 120, 150, 110, 200]\n",
    "})\n",
    "\n",
    "# Set Date as Index (Crucial for Time Series magic)\n",
    "ts_df.set_index('Date', inplace=True)\n",
    "\n",
    "print(\"Time Series:\\n\", ts_df)\n",
    "\n",
    "# Slicing by string!\n",
    "print(\"\\nSales on Jan 3rd:\", ts_df.loc['2024-01-03'])\n",
    "\n",
    "# Resampling (Aggregation over time)\n",
    "# \"Give me the mean sales every 2 Days\"\n",
    "print(\"\\n2-Day Average:\\n\", ts_df.resample('2D').mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
