{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8849622f",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Notebook 1: Python for Deep Learning\n",
    "\n",
    "## 1\\. Introduction\n",
    "\n",
    "This notebook covers the specific subset of Python features that are ubiquitous in Deep Learning. We skip the basics (if statements, basic loops) and focus on:\n",
    "\n",
    "  * **List Comprehensions:** For efficient data preprocessing.\n",
    "  * **Advanced Argument Parsing:** `*args` and `**kwargs` (essential for wrapping models).\n",
    "  * **Object-Oriented Programming:** Specifically `__init__`, `__call__`, and inheritance (the skeleton of every PyTorch model).\n",
    "  * **Type Hinting:** For readable, modern ML code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd85fc4",
   "metadata": {},
   "source": [
    "## 2\\. Pythonic Data Handling: Comprehensions & Slicing\n",
    "\n",
    "Deep learning involves moving massive amounts of data into lists and tensors. Writing \"C-style\" loops is too slow and verbose.\n",
    "\n",
    "### 2.1 List Comprehensions\n",
    "\n",
    "**Why it matters:** You will often need to transform a list of file paths or image labels in one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "871cb5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop result: ['image1.jpg', 'image2.png', 'image3.jpeg']\n"
     ]
    }
   ],
   "source": [
    "# Traditional loop (Avoid this in scripts)\n",
    "files = [\"image1.jpg\", \"image2.png\", \"data.txt\", \"image3.jpeg\"]\n",
    "image_files = []\n",
    "for f in files:\n",
    "    if f.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "        image_files.append(f)\n",
    "\n",
    "print(f\"Loop result: {image_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c086ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pythonic List Comprehension (Preferred)\n",
    "# Syntax: [expression for item in iterable if condition]\n",
    "# It is generally faster and more readable.\n",
    "clean_images = [f for f in files if f.endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
    "\n",
    "print(f\"Comprehension result: {clean_images}\")\n",
    "\n",
    "# Example: Normalizing pixel values (0-255) to (0-1)\n",
    "pixels = [0, 255, 128, 64]\n",
    "normalized = [p / 255.0 for p in pixels]\n",
    "print(f\"Normalized: {normalized}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7bc7bc",
   "metadata": {},
   "source": [
    "### 2.2 Slicing and Indexing\n",
    "\n",
    "**Why it matters:** Slicing lists works exactly like slicing Tensors in NumPy/PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af712c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(range(10)) # [0, 1, 2, ..., 9]\n",
    "\n",
    "print(f\"First 3 items: {data[:3]}\")\n",
    "print(f\"Last 3 items: {data[-3:]}\")\n",
    "print(f\"Every 2nd item: {data[::2]}\")\n",
    "print(f\"Reverse list: {data[::-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa69b84b",
   "metadata": {},
   "source": [
    "## 3\\. Functions & Argument Unpacking\n",
    "\n",
    "In PyTorch, you often wrap layers or functions where you don't know exactly how many arguments will be passed.\n",
    "\n",
    "### 3.1 `*args` and `**kwargs`\n",
    "\n",
    "**Why it matters:** You will see `def forward(self, x, **kwargs):` in almost every transformer implementation to handle optional arguments like attention masks or caching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443471c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, **hyperparameters):\n",
    "    \"\"\"\n",
    "    **kwargs packs keyword arguments into a dictionary.\n",
    "    \"\"\"\n",
    "    print(f\"Training {model_name}...\")\n",
    "    for key, value in hyperparameters.items():\n",
    "        print(f\" -> Setting {key} to {value}\")\n",
    "\n",
    "# Flexible calling\n",
    "train_model(\"ResNet50\", learning_rate=0.01, optimizer=\"Adam\", batch_size=32)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def summary(layer_type, *dimensions):\n",
    "    \"\"\"\n",
    "    *args packs positional arguments into a tuple.\n",
    "    \"\"\"\n",
    "    print(f\"Layer: {layer_type}\")\n",
    "    print(f\"Dimensions: {dimensions}\")\n",
    "\n",
    "summary(\"Conv2d\", 3, 64, 3, 3) # (Channels, Output, KernelH, KernelW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c65ec44",
   "metadata": {},
   "source": [
    "### 3.2 Lambda Functions\n",
    "\n",
    "**Why it matters:** Useful for quick transforms in data loaders (e.g., sorting a list of tuples based on the second element).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d8bddd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted: [('img2.jpg', 0), ('img1.jpg', 1), ('img3.jpg', 1)]\n"
     ]
    }
   ],
   "source": [
    "# List of (file_path, label)\n",
    "dataset = [(\"img1.jpg\", 1), (\"img2.jpg\", 0), (\"img3.jpg\", 1)]\n",
    "\n",
    "# Sort by label\n",
    "sorted_dataset = sorted(dataset, key=lambda x: x[1])\n",
    "print(f\"Sorted: {sorted_dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e565b",
   "metadata": {},
   "source": [
    "## 4\\. Object-Oriented Programming (The PyTorch Way)\n",
    "\n",
    "This is the **most critical section**. Every Neural Network in PyTorch is a class that inherits from `nn.Module`.\n",
    "\n",
    "### 4.1 The `__init__` and `__call__` Duality\n",
    "\n",
    "**Why it matters:**\n",
    "\n",
    "  * `__init__`: Define your layers (weights).\n",
    "  * `__call__`: Define the forward pass (how data flows).\n",
    "  * *Note: In PyTorch, we actually implement `forward()`, but the framework uses `__call__` to trigger hooks.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c7307",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLayer:\n",
    "    def __init__(self, weight):\n",
    "        \"\"\"Initialize weights/parameters here.\"\"\"\n",
    "        self.weight = weight\n",
    "        print(f\"Layer initialized with weight: {self.weight}\")\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        Makes the instance callable like a function: layer(x).\n",
    "        This mimics how PyTorch models work.\n",
    "        \"\"\"\n",
    "        return x * self.weight\n",
    "\n",
    "# Usage\n",
    "layer = SimpleLayer(weight=2.0) # __init__ runs\n",
    "output = layer(5)               # __call__ runs\n",
    "print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7db2977",
   "metadata": {},
   "source": [
    "### 4.2 Inheritance and `super()`\n",
    "\n",
    "**Why it matters:** You never write a model from scratch; you always extend a base class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f236aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "    def save(self):\n",
    "        print(\"Saving model to disk...\")\n",
    "\n",
    "class Classifier(BaseModel):\n",
    "    def __init__(self, num_classes):\n",
    "        # critical: initialize the parent class\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def predict(self, x):\n",
    "        return f\"Predicting {x} into {self.num_classes} classes.\"\n",
    "\n",
    "model = Classifier(num_classes=10)\n",
    "print(model.predict(\"image_data\"))\n",
    "model.save() # Inherited methodc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f009a4c8",
   "metadata": {},
   "source": [
    "\n",
    "## 5\\. Modern Python: Typing and Dataclasses\n",
    "\n",
    "Deep learning codebases can get messy. Modern Python features help keep them clean.\n",
    "\n",
    "### 5.1 Type Hinting\n",
    "\n",
    "**Why it matters:** Helps your IDE (VS Code/PyCharm) autocomplete and catch errors before you run a 3-hour training job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341349d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Optional\n",
    "\n",
    "def preprocess_batch(images: List[str], size: int = 256) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        images: A list of filenames\n",
    "        size: Target resize dimension\n",
    "    Returns:\n",
    "        Tuple of (batch_size, image_size)\n",
    "    \"\"\"\n",
    "    return len(images), size\n",
    "\n",
    "# The hints don't enforce types at runtime, but they are crucial for documentation\n",
    "print(preprocess_batch([\"img1\", \"img2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028ad8fb",
   "metadata": {},
   "source": [
    "### 5.2 Dataclasses for Configuration\n",
    "\n",
    "**Why it matters:** Instead of passing massive dictionaries of hyperparameters (learning rate, epochs, dropout) around, use Dataclasses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff6702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    learning_rate: float\n",
    "    batch_size: int\n",
    "    epochs: int = 10 # Default value\n",
    "    use_gpu: bool = True\n",
    "\n",
    "# Usage\n",
    "config = TrainingConfig(learning_rate=1e-4, batch_size=64)\n",
    "\n",
    "print(f\"Config: {config}\")\n",
    "print(f\"LR: {config.learning_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aa7d53",
   "metadata": {},
   "source": [
    "## 6\\. Useful Standard Libraries for ML\n",
    "\n",
    "A few built-in libraries appear constantly.\n",
    "\n",
    "  * `pathlib`: Modern file path handling (replaces `os.path`).\n",
    "  * `tqdm`: Progress bars (essential for training loops)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc3d72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pathlib example\n",
    "from pathlib import Path\n",
    "\n",
    "# Create a dummy path object (works on Windows/Linux/Mac automatically)\n",
    "p = Path(\"data/images\")\n",
    "print(f\"Parent directory: {p.parent}\")\n",
    "print(f\"Absolute path: {p.resolve()}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# TQDM Example (You may need to install it: pip install tqdm)\n",
    "# This creates a progress bar for your loops.\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Training simulation...\")\n",
    "for i in tqdm(range(5)):\n",
    "    time.sleep(0.1) # Simulate work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0391f94",
   "metadata": {},
   "source": [
    "## 7\\. Comprehensive Checkpoint & Challenge\n",
    "\n",
    "To ensure you are ready to move on, try to solve this mini-challenge without looking back at the code above.\n",
    "\n",
    "**The Challenge:**\n",
    "Create a class `ImageLoader` that simulates a deep learning data pipeline.\n",
    "\n",
    "1.  **`__init__`**: Accepts a list of file paths and a `target_size` (int).\n",
    "2.  **`__call__`**: Accepts an index `i`. It should return a dictionary `{'path': ..., 'size': ...}` for the file at that index.\n",
    "3.  **Process**: Filter out any file that doesn't end in `.jpg` using a list comprehension.\n",
    "4.  **Bonus**: Use a dataclass to store the configuration (paths and size).\n",
    "\n",
    "**Self-Evaluation Checklist:**\n",
    "\n",
    "  * [ ] Can I write a list comprehension to filter or transform data in one line?\n",
    "  * [ ] Do I understand that `model(x)` actually calls the `__call__` method?\n",
    "  * [ ] Am I comfortable using `**kwargs` to pass optional arguments?\n",
    "  * [ ] Do I understand why `super().__init__()` is necessary in inheritance?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
